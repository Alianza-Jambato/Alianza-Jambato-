---
title: "Código - Procesamiento Climático Angamarca"
author: "Michelle Rodriguez, Raul Ontaneda & Andrés Mármol"
format: html
editor: visual
---

# Código de interpretación de datos de la estación meteorológica.

Esta libreta contiene información de cómo procesar los datos tomados desde la estación meteorológica de la Alianza Jambato, ubicada en Angamarca, cerca del área núcleo donde se encuentra la última población conocida del jambato. Esta libreta ha sido creada gracias al trabajo de Michelle Rodríguez, Raúl Ontadena & Andrés Mármol, durante el periodo de voluntariados de la Alianza Jambato comprendidos entre Julio y Octubre de 2024.

Para más información, contactarse con María del Carmen Vizcaino Barba (MCVB).(mcvizcaino\@alianzajambato.org).

## 1. Descargando los datos.

La estación meteorológica de la Alianza Jambato envía los datos diarios a la nube através del internet. Los datos pueden ser visualizados en [www.ambientweather.net](https://ambientweather.net/), e iniciar sesión con las credenciales de la alianza (adquirirlas con MCVB).

**NOTA:** La descarga de datos debe realizarse mensualmente, ya que pasado el año, los datos obtenidos se borran automaticamente.

**NOTA:** Es importante revisar el estado de las baterías AA y AAA que operan en la estación científica periódicamente. Se puede encontrar información respecto a esto en el Dashboard de inicio al iniciar sesión en Ambient Weather.

Una vez ingresado, uno se dirige hacia la pestaña "Graphs & Tables" y posteriormente se hace click sobre las fechas para seleccionar el rango de días a descargarse (fig 1.1).

![Fig 1.1. Frontend de ambient weather. En la parte derecha se puede ver un menú desplegable que permite especificar el periodo de tiempo para descargar los datos.](wn%20images/Screenshot%202025-05-12%20at%2020.29.01%20con%20flecha.png)

Una vez especificada la fecha, la imagen cambia a las variaciones dentro del rango seleccionado. Para descargar los datos primero se solicita que se resuman los datos (fig 1.2) y posteriomente se procede a seleccionar "Export all data" (figura 1.3).

![Fig 1.2. Resumen de datos. Aquí finalmente se da click en en ícono de la derecha (con el círculo azul) y se procede a seleccionar todos los datos.)](wn%20images/Screenshot%202025-05-12%20at%2020.32.32.png)

Los archivos resultantes son guardados en el repositorio de la Alianza Jambato que actualmente se encuentra en la cuenta de Google Drive (el repositorio será migrado a OneDrive).

## 2. Procesando los datos.

Antes de empezar se debe llamar a todos los paquetes de R que se utilizarán dentro de este ejercicio. Los paquetes son `readr`, `tidyr`, `dplyr`, `clock`, `ggplot2` & `lubridate`.

```{r, echo=TRUE, message=FALSE, warning=FALSE}
library(tidyr)
library(dplyr)
library(ggplot2)
library(clock)
library(readr)
library(lubridate)
```

El procesamiento de datos hasta esta fase incluye el poder llamar, harmonizar (e.g. asignar formatos), e integrar las tablas mensuales en un archivo unido. Para esto se deben abrir todos los archivos dentro del repositorio para posteriormente integrarlos.

El primer paso es llamar a los datos una vez estos sean descargados localmente. Esta parte del código dependerá de dónde se descarguen los datos en el computador de cada uno. El uso de "\\" o "/" dependerá tambien del sistema operativo en uso.

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# estableciendo la dirección de CSVs en mi computador local

folder_path <- "/Users/andresmarmolguijarro/Downloads/meteor"
  
# enlistando todos los CSVs dentro de este archivo
  
csv_list <- list.files(path = folder_path, pattern = "\\.csv$", full.names = TRUE)
```

Finalmente se llaman a todos los csvs mensuales

```{r, echo=TRUE, message=FALSE, warning=FALSE}
csvs<- lapply(csv_list, read_csv)
```

**Nota:** Un paso adicional que ayuda a general un solo archivo consolidado es el siguiente:

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# crea una función para llamar a todos los CSVs

csvsall <- lapply(csv_list, function(file){
  read_csv(file) |> mutate(source_file = basename(file))
})

# agregan todos los archivos en un solo data frame llamado dfall

dfall <- bind_rows(csvsall)
```

Al final obtenemos un solo dataset que consta de 125901 filas x 27 columnas. Este dataset va desde septiembre de 2023 hasta febrero de 2024. El numero de filas variaría si se añaden datos anteriores y/o posteriores a la fechas especificadas.

```{r}
str(dfall)
```

### 2.1. Reorganizando las columnas internas del dataset.

El dataset original cuenta con las columnas `Date` y `Simple Date`. El primer paso a tomar en este sentido es reconfigurar la tabla de tal manera que podamos formatear las fechas de manera homogenea y legible para R

```{r}
# aseguramos de que el data frame sea un tibble para la ejecución de las transformaciones en dplyr y limpiamos los nombres de las columnas (algunos poseen sintaxis incorrecta al mostrar espacios entre palabras)

dfall <- as_tibble(dfall)
dfall <- janitor::clean_names(dfall)
```

Ahora se formatean los datos contenidos en la columna `Simple.Date` usando la función `as.POSIXct()` del paquete **`lubridate`**

```{r}
# nos permite ver cual es el nombre de la variable
names(dfall)
```

```{r}
# la variable de interes es "simple_date" y se crea una nueva columna llamada "NewDate"

dfall$new_date <- as.POSIXct(dfall$simple_date)
dfall$new_date <- format(dfall$new_date, "%Y-%m-%d %H:%M:%S")

dfall$new_date_bkp = dfall$new_date
```

Ahora se separa `NewDate` en dos columnas: una para fecha y una para hora.

```{r}
dfall <-  separate(dfall, new_date, sep=" ",
              into = c("date", "time"))
```

## 3. Analizando y realizando figuras

En el primer caso vamos a analizar la temperatura por semana. Para esto vamos a crear una nueva tabla a partir de `dfall`

Primero, a partir de la columna date_2, extraemos valores importantes que serán codificados en forma de columna. Por ejemplo, el año y el número de semana iran en su columna independiente.

```{r}
dfall$week <-isoweek(dfall$date) # extrae las semanas
dfall$year <- year(dfall$date)
```

Ahora vamos a generar el primer gráfico de temperatura por año, por semana. Para esto usaremos la función `group_by()` & `summarise()` del paquete de `dplyr`

```{r}
# na.rm = TRUE removes NAs, whereas na.rm = FALSE do not remove NAs

t <- dfall %>%
  group_by(year, week) %>%
  summarise(
    mean_temp = mean(outdoor_temperature_c, na.rm = TRUE),  
    min_temp = min(outdoor_temperature_c, na.rm = TRUE),
    max_temp = max(outdoor_temperature_c, na.rm = TRUE),
    .groups = 'drop'
  )
```

Para el gráfico se usa `ggplot2`

```{r}
temp_anual <- ggplot(data = t, aes(x=week, y=mean_temp, group=year))+
  
  geom_ribbon(aes(ymin = min_temp,
                  ymax = max_temp,
                  fill = as.factor(year)),
              alpha = 0.25) +
  
  geom_line(aes(colour=as.factor(year))) +
  
  labs(x = "semana",
       y = "temperatura (°C)",
       fill = "Rango",
       colour = "Promedio")+
  
  scale_fill_manual(values = c("2023" = "#b1babc",
                             "2024" = "#68bcbc",
                             "2025" = "#499AE0"))+
  
  scale_colour_manual(values = c("2023" = "#b1babc",
                                 "2024" = "#68bcbc",
                                 "2025" = "#499AE0"))+
  
  theme_minimal()+
  
  theme(axis.text.x = element_text (angle= 45,
                                    hjust= 1))
```

```{r}
temp_anual
```

```{r}
td <- ggplot(dfall, aes(x=as.Date(new_date_bkp), y=outdoor_temperature_c, group = year))+
  geom_line(aes(colour=year))
```

```{r}
td
```

## 4. Ubicación de la estación meteorológica en Angamarca.

```{r}
library(leaflet)

leaflet() %>%
  addTiles() %>%
  addMarkers(lng = -78.906386, lat = -1.127606, popup = "1.13°S, 78.91°W") %>%
  setView(lng = -78.906386, lat = -1.127606, zoom = 8)
```
